---
slug: "generate-unit-tests"
description: "指定されたファイル/モジュールに対して単体テストを設計→生成→実行→検証（回帰なしの根拠）まで行う。スタックはSoT（brief.md）に従い、外部依存はモック戦略で隔離する。"
trigger: "manual"
---
# 🧪 generate-unit-tests — 単体テスト生成

単体テストは「書いた」ではなく、**仕様の境界を固定し、回帰を防ぐ証拠**です。  
Convoy では、テスト生成を **計画 → 生成 → 実行 → 失敗時の収束 → 記録**まで一気通貫で行います。

---

## 定義（このワークフローの狙い）
- 対象ファイルの **公開API（public surface）** を洗い出し、テスト計画を作る
- 外部依存（DB/API/FS/時刻/乱数等）を **モック戦略**で隔離し、テストを安定化する
- テストを実行して **Pass を証明**し、必要なら最小修正で収束させる
- カバレッジを参考指標として報告し、次の改善アクションを提示する

---

## SoT（Source of Truth）
- スタック/テストランナー/コマンド: `assets/branding/<productId>/brief.md`
- 利用可能コマンド一覧: `.agent/INDEX.md`
- 品質/安全: `.agent/rules/*.md`（security/type-safety 等）
- 管制仕様: `ANTIGRAVITY_AGENT_CONTROL_SPEC.md`

---

## 入力（ユーザーから受け取る情報）
- 対象ファイルパス（必須）
- 対象範囲（任意）：`全public` / `特定関数だけ` / `特定クラスだけ`
- 期待仕様（任意）：期待する振る舞い、既知のバグ、境界値
- 実行環境（任意）：Web/Flutter/Python 等（ただし最終判断は brief.md を正本とする）

---

## 成果物（Outputs）
- テストファイル（例: `__tests__/...` / `tests/...`）
- 実行結果（コマンドログ要約）
- 追加したテストケース一覧（計画→実装の対応）
- 失敗した場合の原因と対処（必要なら）

---

## 重要ルール（Convoy品質ガード）
- **SoT参照**: テストフレームワークやコマンドを勝手に固定しない（brief.md を参照）
- **安定性重視**: フレイキー（不安定）なテストは作らない（時刻/乱数/ネットワークは固定）
- **外部依存は隔離**: DB/API/FS は原則モック。統合テストに逃げない
- **実装を変える場合は最小**: テストのための過剰なリファクタは禁止（必要なら提案→承認）
- **危険操作は承認必須**: 依存追加、設定変更、push/リリース等はユーザー確認

---

# 手順

## Step 1: コンテキスト分析（対象のpublic surfaceを確定） // turbo
対象ファイルを読み込み、以下を特定する：

- 公開API（export/public な関数・クラス・メソッド）
- 入出力（パラメータ、戻り値、例外、エラー表現）
- 副作用（I/O、HTTP、DB、ファイル、時刻、ランダム、グローバル状態）
- 分岐と境界（条件分岐、境界値、null/undefined、空配列、異常系）
- 依存関係（外部モジュール、DI、環境変数、設定）

**出力（必須）**
- Public surface 一覧（箇条書き）
- 依存/副作用一覧（モック対象候補）

---

## Step 2: テスト計画（ケース一覧を作って提示）
分析結果に基づき、テストケースのリストを作成し、ユーザーに提示する。  
各ケースに含めること：

- 対象（関数/メソッド/クラス）
- シナリオ（Given/When/Then が望ましい）
- 期待結果（戻り値、例外、状態変化、呼び出し回数）
- モック要否（何を固定するか）

**計画テンプレ（例）**
- `<target>`: 正常系（代表ケース）
- `<target>`: 境界値（min/max/empty/null）
- `<target>`: 異常系（例外/エラー）
- `<target>`: 依存呼び出し（API/DB/FS）をモックして検証

> ここで「何をテストするか」を先に合意する。  
> テスト生成は、計画が命。

---

## Step 3: モック戦略（安定テストの設計）
外部依存の扱いを決める。

### 原則（推奨）
- DB接続: **モック必須**（インメモリ代替も可だが unit ではない）
- 外部API: **モック必須**
- ファイルシステム: 可能ならモック（どうしても必要なら一時ディレクトリで隔離）
- 時刻/乱数: **固定**（fake timer / seed / clock injection）
- グローバル状態: テストごとにリセット（beforeEach/afterEach）

**出力（必須）**
- 「モック対象」と「モック方法」の一覧

---

## Step 4: テスト実装（ファイル配置と命名）
`brief.md` のスタックに従い、適切な場所・命名でテストファイルを作成する。

- 例（TypeScript）: `__tests__/<name>.test.ts` / `tests/<name>.test.ts`
- 例（Python）: `tests/test_<name>.py`

**必須**
- Arrange / Act / Assert を明確に
- 期待結果を読みやすく（マジックナンバーは理由をつける）
- モックは最小（必要なところだけ）

---

## Step 5: 実行と収束（Fail→Pass） // turbo
テストを実行する（コマンドは brief.md に従う）。例：

### Web（Node系の例）
```bash
pnpm test
```

### Python の例
```bash
pytest
```

### Flutter の例
```bash
flutter test
```

失敗した場合：
1. エラーログを要約し、失敗理由を分類（テスト不備 / 実装修正必要 / 環境）
2. **最小変更**で収束させる（原則はテスト側で修正。実装が原因なら最小修正）
3. 最大リトライは **2回**まで（無限ループを避ける）
4. 収束できない場合は、原因と次の打ち手（要確認点）を提示して停止

---

## Step 6: カバレッジ（参考指標として報告）
カバレッジは「目標」ではなく「ヒント」。以下を報告する。

- 全体（%）
- 対象ファイル（%）
- 未カバーの重要分岐（あれば）

**注意**
- カバレッジ上げのための無意味なテストは禁止
- 重要なのは「壊れやすい境界が守れているか」

---

## Step 7: 完了報告（Convoy標準フォーマット）
```markdown
## ✅ generate-unit-tests 完了

### 対象
- <file>
- 範囲: <全public / 特定>

### 追加したテスト
- <case 1>
- <case 2>

### モック戦略
- <dependency>: <how>

### 実行結果（Evidence）
- コマンド: <...>
- 結果: Pass / Fail
- 失敗があった場合: <原因と対処>

### カバレッジ（参考）
- 全体: <...>
- 対象: <...>
- 未カバー重要点: <...>

### 次のアクション（任意）
- <追加で守るべき境界 / 統合テスト提案 / リファクタ提案>
```


